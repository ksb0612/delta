import streamlit as st
import pandas as pd
import numpy as np
import copy
import yaml
import streamlit_authenticator as stauth
import os
import json
from scipy.stats import weibull_min
import hashlib
from plotly.subplots import make_subplots
from visualization import (
    create_roas_distribution_figure, create_timeseries_figure, create_retention_curve_figure,
    create_sensitivity_figure, create_profit_cdf_figure, create_convergence_figure,
    create_backtesting_figure, create_profit_histogram, create_profit_kde_plot,
    create_cost_efficiency_analysis, create_performance_contribution_analysis
)



from utils import (
    load_config, format_number, calculate_errors,
    flatten_scenario_df, reconstruct_scenario_from_df
)
from advanced_simulator import AdvancedLaunchSimulator
from analysis import StrategicAnalyzer


SCENARIOS_DIR = "scenarios"

# --- Caching Functions ---
@st.cache_data
def create_settings_hash(project_info, assumptions, scenario_template, arppu_params):
    """ëª¨ë“  ì„¤ì •ì˜ í•´ì‹œê°’ì„ ìƒì„±í•˜ì—¬ ë³€ê²½ì‚¬í•­ì„ ì •í™•íˆ ê°ì§€"""
    settings = {
        "project_info": project_info,
        "assumptions": assumptions,
        "scenario_template": scenario_template,
        "arppu_params": arppu_params
    }
    
    # JSONìœ¼ë¡œ ì§ë ¬í™” í›„ í•´ì‹œ ìƒì„±
    settings_str = json.dumps(settings, default=convert_numpy_to_native, sort_keys=True)
    return hashlib.md5(settings_str.encode()).hexdigest()

@st.cache_data
def run_cached_simulation(settings_hash: str, project_info, assumptions, num_simulations, scenario_template, arppu_params):
    """ì„¤ì • í•´ì‹œê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ìºì‹±í•˜ëŠ” ì‹œë®¬ë ˆì´ì…˜ í•¨ìˆ˜"""
    simulator = AdvancedLaunchSimulator(project_info, assumptions, num_simulations, scenario_template, arppu_params)
    results = simulator.run_monte_carlo()
    return results


@st.cache_data
def run_cached_sensitivity_analysis(_config_str, _scenario_data_str):
    _config = json.loads(_config_str)
    _scenario_data = json.loads(_scenario_data_str)
    analyzer = StrategicAnalyzer(_config)
    return analyzer.run_sensitivity_analysis(_scenario_data)

# --- Scenario Management Functions ---
def load_scenario_names():
    if not os.path.exists(SCENARIOS_DIR):
        return []
    try:
        files = [f for f in os.listdir(SCENARIOS_DIR) if f.endswith((".yaml", ".yml"))]
        return sorted([os.path.splitext(f)[0] for f in files])
    except IOError as e:
        st.error(f"ì‹œë‚˜ë¦¬ì˜¤ í´ë”ë¥¼ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

def convert_numpy_to_native(data):
    if isinstance(data, dict):
        return {key: convert_numpy_to_native(value) for key, value in data.items()}
    elif isinstance(data, list):
        return [convert_numpy_to_native(element) for element in data]
    elif isinstance(data, np.integer):
        return int(data)
    elif isinstance(data, np.floating):
        return float(data)
    elif isinstance(data, pd.DataFrame):
        return data.to_dict(orient='split')
    elif isinstance(data, np.ndarray):
        return data.tolist()
    else:
        return data

def save_scenario(name, media_df, organic_df):
    if not name:
        st.warning("ì‹œë‚˜ë¦¬ì˜¤ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return
    sanitized_name = "".join(c for c in name if c.isalnum() or c in (' ', '_', '-')).rstrip()
    if not sanitized_name:
        st.warning("ìœ íš¨í•œ ì‹œë‚˜ë¦¬ì˜¤ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì•ŒíŒŒë²³, ìˆ«ì, ê³µë°±, _, - ë§Œ í—ˆìš©)")
        return
    filename = f"{sanitized_name}.yaml"
    filepath = os.path.join(SCENARIOS_DIR, filename)
    os.makedirs(SCENARIOS_DIR, exist_ok=True)
    scenario_data = {
        'media_mix': reconstruct_scenario_from_df(media_df.copy(), 'media_mix'),
        'organic_assumptions': reconstruct_scenario_from_df(organic_df.copy(), 'organic')
    }
    native_data = convert_numpy_to_native(scenario_data)
    try:
        with open(filepath, "w", encoding="utf-8") as f:
            yaml.dump(native_data, f, allow_unicode=True, sort_keys=False, default_flow_style=False)
        st.success(f"'{name}' ì‹œë‚˜ë¦¬ì˜¤ê°€ '{filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.session_state.scenario_files = load_scenario_names()
    except IOError as e:
        st.error(f"ì‹œë‚˜ë¦¬ì˜¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# --- Page Config & Initialization ---
st.set_page_config(layout="wide", page_title="ë¯¸ë””ì–´ë¯¹ìŠ¤ ì‹œë®¬ë ˆì´í„°")

if 'config' not in st.session_state:
    st.session_state.config = load_config()
if 'project_info' not in st.session_state:
    st.session_state.project_info = st.session_state.config['project_info']
if 'assumptions' not in st.session_state:
    st.session_state.assumptions = st.session_state.config['assumptions']
if 'simulation_results' not in st.session_state:
    st.session_state.simulation_results = {}
if 'media_mix_df' not in st.session_state:
    df = flatten_scenario_df(st.session_state.config['scenario_template'], 'media_mix')
    df.drop(columns=[col for col in df.columns if 'retention' in col and 'scale' in col], inplace=True, errors='ignore')
    st.session_state.media_mix_df = df
if 'organic_df' not in st.session_state:
    df = flatten_scenario_df(st.session_state.config['scenario_template'], 'organic')
    df.drop(columns=[col for col in df.columns if 'retention' in col and 'scale' in col], inplace=True, errors='ignore')
    st.session_state.organic_df = df
if 'scenario_files' not in st.session_state:
    st.session_state.scenario_files = load_scenario_names()
if 'show_add_organic_form' not in st.session_state:
    st.session_state.show_add_organic_form = False
if 'show_add_channel_form' not in st.session_state:
    st.session_state.show_add_channel_form = False
if 'page' not in st.session_state:
    st.session_state.page = "ëŒ€ì‹œë³´ë“œ & ê²°ê³¼"
if 'last_run_settings_signature' not in st.session_state:
    st.session_state.last_run_settings_signature = None


# --- UI Rendering Functions ---
def render_dashboard_summary(final_df, project_info, assumptions):
    st.subheader("ğŸ¯ ìµœì¢… ì„±ê³¼ ìš”ì•½")
    col1, col2, col3 = st.columns(3)
    median_roas = final_df['paid_roas'].median()
    median_revenue = final_df['paid_revenue'].median()
    total_budget = project_info['target_budget']
    median_profit = final_df['total_profit'].median()
    median_roi = median_profit / total_budget if total_budget > 0 else 0
    with col1:
        st.metric("ì˜ˆì¸¡ ROAS (ì¤‘ì•™ê°’)", f"{median_roas:.2%}", help="ê´‘ê³ ë¹„ ëŒ€ë¹„ ìœ ë£Œ ì±„ë„ ë§¤ì¶œ")
        st.caption("`ê³„ì‚°ì‹: ìœ ë£Œ ì±„ë„ ë§¤ì¶œ / ì´ ê´‘ê³ ë¹„`")
        st.markdown(f"**ì˜ˆìƒ ìœ ë£Œ ë§¤ì¶œ:** {format_number(median_revenue, True)}")
    with col2:
        st.metric("ì˜ˆì¸¡ ROI (ì¤‘ì•™ê°’)", f"{median_roi:.2%}", help="ê´‘ê³ ë¹„ ëŒ€ë¹„ ì „ì²´ ìˆœìˆ˜ìµ")
        st.caption("`ê³„ì‚°ì‹: ì´ ìˆœìˆ˜ìµ / ì´ ê´‘ê³ ë¹„`")
        st.markdown(f"**ì˜ˆìƒ ì „ì²´ ìˆœìˆ˜ìµ:** {format_number(median_profit, True)}")
    with col3:
        render_target_guide(final_df, project_info, assumptions)

def render_target_guide(final_df, project_info, assumptions):
    with st.container(border=True):
        st.markdown("##### ğŸ¯ ëª©í‘œ ë‹¬ì„± ê°€ì´ë“œ")
        target_roas = project_info['target_roas']
        st.markdown(f"**ëª©í‘œ ROAS:** `{target_roas:.1%}`")

        # ê¸°ë³¸ ê³„ì‚°ê°’ë“¤ (ìœ ë£Œ ì±„ë„ ê¸°ì¤€)
        paid_installs_median = final_df['paid_installs'].median()
        paid_revenue_median = final_df['paid_revenue'].median()
        paid_pcr_median = final_df['paid_paying_users'].median() / paid_installs_median if paid_installs_median > 0 else 0
        total_budget = project_info['target_budget']

        # ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ í•„ìš” ìœ ë£Œ ìˆ˜ìµ
        required_paid_revenue = target_roas * total_budget
        
        # CPI (ìƒí•œ)
        paid_cpi_median = final_df['paid_cpi'].median()
        improvement_factor = required_paid_revenue / paid_revenue_median if paid_revenue_median > 0 else np.nan
        required_paid_cpi = paid_cpi_median / improvement_factor if not np.isnan(improvement_factor) else np.nan

        # LTV, ARPU, ARPPUë¥¼ 30ì¼ ê¸°ì¤€ìœ¼ë¡œ ì¬ê³„ì‚°
        from scipy.stats import weibull_min
        ltv_cfg = assumptions['ltv_curve']
        shape, scale = ltv_cfg['shape'], ltv_cfg['scale']
        
        # ì „ì²´ LTV ê¸°ê°„ ëŒ€ë¹„ 30ì¼ì°¨ì˜ ë§¤ì¶œ ë¹„ì¤‘
        ltv_duration = project_info.get('ltv_duration_days', 30)
        total_ltv_ratio = weibull_min.cdf(ltv_duration, c=shape, scale=scale)
        ltv_ratio_d30 = weibull_min.cdf(30, c=shape, scale=scale)
        
        # ì „ì²´ ê¸°ê°„ ë™ì•ˆì˜ í•„ìš” ìœ ë£Œ ìˆ˜ìµì„ 30ì¼ ê¸°ì¤€ìœ¼ë¡œ í™˜ì‚°
        required_paid_revenue_d30 = required_paid_revenue * (ltv_ratio_d30 / total_ltv_ratio) if total_ltv_ratio > 0 else required_paid_revenue
        
        # 30ì¼ ê¸°ì¤€ ëª©í‘œ ARPU ë° ARPPU
        required_paid_arpu_d30 = required_paid_revenue_d30 / paid_installs_median if paid_installs_median > 0 else 0
        paid_paying_users_median = paid_installs_median * paid_pcr_median
        required_paid_arppu_d30 = required_paid_revenue_d30 / paid_paying_users_median if paid_paying_users_median > 0 else 0

        # ë‹¨ê¸° LTV ëª©í‘œ ê³„ì‚°
        days = [3, 7, 14]
        cumulative_ltv_ratios = {day: weibull_min.cdf(day, c=shape, scale=scale) for day in days}
        
        # 30ì¼ ARPUë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê° ì‹œì ë³„ LTV ê³„ì‚°
        required_ltv_d3 = required_paid_arpu_d30 * (cumulative_ltv_ratios[3] / ltv_ratio_d30) if ltv_ratio_d30 > 0 else 0
        required_ltv_d7 = required_paid_arpu_d30 * (cumulative_ltv_ratios[7] / ltv_ratio_d30) if ltv_ratio_d30 > 0 else 0
        required_ltv_d14 = required_paid_arpu_d30 * (cumulative_ltv_ratios[14] / ltv_ratio_d30) if ltv_ratio_d30 > 0 else 0
        
        # ê²°ê³¼ ì¶œë ¥ (D+30ì¼ LTVëŠ” ARPU D30ê³¼ ë™ì¼)
        st.markdown(f"**ìœ ë£Œ CPI (ìƒí•œ):** `{format_number(required_paid_cpi, True)}`")
        st.markdown(f"**ìœ ë£Œ ARPPU D30 (ìµœì†Œ):** `{format_number(required_paid_arppu_d30, True)}`")
        st.markdown(f"**ìœ ë£Œ ARPU D30 (ìµœì†Œ):** `{format_number(required_paid_arpu_d30, True)}`")
        st.markdown(f"**ìœ ë£Œ D+3ì¼ LTV (ìµœì†Œ):** `{format_number(required_ltv_d3, True)}`")
        st.markdown(f"**ìœ ë£Œ D+7ì¼ LTV (ìµœì†Œ):** `{format_number(required_ltv_d7, True)}`")
        st.markdown(f"**ìœ ë£Œ D+14ì¼ LTV (ìµœì†Œ):** `{format_number(required_ltv_d14, True)}`")
        st.markdown(f"**ìœ ë£Œ D+30ì¼ LTV (ìµœì†Œ):** `{format_number(required_paid_arpu_d30, True)}`")


def render_detailed_metrics(final_df):
    st.subheader("ğŸ“ˆ ìƒì„¸ ì§€í‘œ ë¶„ì„ (ì¤‘ì•™ê°’ ê¸°ì¤€)")
    
    kpi_metrics = {
        "ì´ìˆ˜ìµ": ("total_revenue", True, 0, "ìœ ë£Œ ìˆ˜ìµ + ì˜¤ê°€ë‹‰ ìˆ˜ìµ"),
        "ìœ ë£Œ ìˆ˜ìµ": ("paid_revenue", True, 0, "ëª¨ë“  ìœ ë£Œ ì±„ë„ì—ì„œ ë°œìƒí•œ ëˆ„ì  ë§¤ì¶œ"),
        "ì´ ìˆœìˆ˜ìµ": ("total_profit", True, 0, "ì´ìˆ˜ìµ - ì´ ê´‘ê³ ë¹„"),
        "ì´ ì„¤ì¹˜ ìˆ˜": ("total_installs", False, 0, "ìœ ë£Œ ì„¤ì¹˜ ìˆ˜ + ì˜¤ê°€ë‹‰ ì„¤ì¹˜ ìˆ˜"),
        "ì˜¤ê°€ë‹‰ ì„¤ì¹˜ ìˆ˜": ("organic_installs", False, 0, "ìì—°ì ìœ¼ë¡œ ë°œìƒí•œ ëˆ„ì  ì„¤ì¹˜ ìˆ˜"),
        "ìœ ë£Œ ì„¤ì¹˜ ìˆ˜": ("paid_installs", False, 0, "ëª¨ë“  ìœ ë£Œ ì±„ë„ì—ì„œ ë°œìƒí•œ ëˆ„ì  ì„¤ì¹˜ ìˆ˜"),
        "ì „ì²´ CPI": ("blended_cpi", True, 0, "ì´ ê´‘ê³ ë¹„ / ì´ ì„¤ì¹˜ ìˆ˜"),
        "ìœ ë£Œ CPI": ("paid_cpi", True, 0, "ì´ ê´‘ê³ ë¹„ / ìœ ë£Œ ì„¤ì¹˜ ìˆ˜"),
        "ì „ì²´ ARPU": ("blended_arpu", True, 0, "ì´ìˆ˜ìµ / ì´ ì„¤ì¹˜ ìˆ˜"),
        "ì „ì²´ ARPPU": ("blended_arppu", True, 0, "ì´ìˆ˜ìµ / ì´ ê²°ì œ ìœ ì € ìˆ˜"),
    }

    df_for_display = final_df.copy()
    if 'total_installs' in df_for_display.columns and 'paid_installs' in df_for_display.columns:
        df_for_display['organic_installs'] = df_for_display['total_installs'] - df_for_display['paid_installs']

    # ë°ì´í„°ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    metrics_data = []

    # ê° ì§€í‘œì— ëŒ€í•´ ê³„ì‚° ë° í¬ë§·íŒ…
    for key, (metric_key, is_currency, dec, explanation) in kpi_metrics.items():
        if metric_key in df_for_display.columns:
            median_val = df_for_display[metric_key].median()
            p10 = df_for_display[metric_key].quantile(0.1)
            p90 = df_for_display[metric_key].quantile(0.9)
            
            metrics_data.append({
                "ì§€í‘œ": key,
                "P10": format_number(p10, is_currency, dec),
                "ì¤‘ì•™ê°’ (P50)": format_number(median_val, is_currency, dec),
                "P90": format_number(p90, is_currency, dec),
                "ê³„ì‚°ì‹": explanation
            })

    # ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° ì¶œë ¥
    if metrics_data:
        metrics_df = pd.DataFrame(metrics_data)
        st.dataframe(metrics_df, use_container_width=True, hide_index=True)

def render_breakdown_tables(all_df):
    st.subheader("ğŸ“Š ì±„ë„ë³„/êµ­ê°€ë³„ ìƒì„¸ ì„±ê³¼")
    st.caption("ê° ì±„ë„ ë° êµ­ê°€ë³„ ì„±ê³¼ì˜ ì¤‘ì•™ê°’(Median)ì…ë‹ˆë‹¤. ì»¬ëŸ¼ í—¤ë”ë¥¼ í´ë¦­í•˜ì—¬ ì •ë ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    paid_df = all_df[all_df['type'] != 'Organic'].copy()
    if paid_df.empty:
        st.info("ì„±ê³¼ë¥¼ ë¶„ì„í•  ìœ ë£Œ ì±„ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ê° ì‹œë®¬ë ˆì´ì…˜ë³„, ì±„ë„ë³„ ìµœì¢… ì„±ê³¼ ì§‘ê³„
    channel_summary_per_sim = paid_df.groupby(['sim_id', 'os', 'country', 'name']).agg(
        total_spend=('spend', 'sum'),
        total_revenue=('revenue', 'sum'),
        total_installs=('installs', 'sum')
    ).reset_index()

    # ì±„ë„ë³„ ì¤‘ì•™ê°’ ì„±ê³¼ ê³„ì‚°
    median_performance = channel_summary_per_sim.drop(columns='sim_id').groupby(['os', 'country', 'name']).median().reset_index()

    # ìµœì¢… ì§€í‘œ ê³„ì‚°
    median_performance['ROAS'] = median_performance['total_revenue'] / median_performance['total_spend'].replace(0, np.nan)
    median_performance['CPI'] = median_performance['total_spend'] / median_performance['total_installs'].replace(0, np.nan)
    median_performance['Profit'] = median_performance['total_revenue'] - median_performance['total_spend']

    # êµ­ê°€ë³„ ì„±ê³¼ ì§‘ê³„
    country_summary = median_performance.groupby('country').agg(
        total_spend=('total_spend', 'sum'),
        total_revenue=('total_revenue', 'sum'),
        total_installs=('total_installs', 'sum')
    ).reset_index()
    country_summary['ROAS'] = country_summary['total_revenue'] / country_summary['total_spend'].replace(0, np.nan)
    country_summary['CPI'] = country_summary['total_spend'] / country_summary['total_installs'].replace(0, np.nan)
    country_summary['Profit'] = country_summary['total_revenue'] - country_summary['total_spend']


    # UI íƒ­ ìƒì„±
    tab1, tab2 = st.tabs(["ğŸ“ˆ êµ­ê°€ë³„ ìš”ì•½", "ğŸ“‹ ì±„ë„ë³„ ìƒì„¸"])

    with tab1:
        st.dataframe(
            country_summary.style.format({
                "total_spend": "{:,.0f}ì›",
                "total_revenue": "{:,.0f}ì›",
                "total_installs": "{:,.0f}",
                "ROAS": "{:.2%}",
                "CPI": "{:,.0f}ì›",
                "Profit": "{:,.0f}ì›"
            }),
            use_container_width=True
        )
    
    with tab2:
        # ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½ ë° ìˆœì„œ ì •ë¦¬
        channel_detail_display = median_performance.rename(columns={
            'os': 'OS', 'country': 'êµ­ê°€', 'name': 'ì±„ë„',
            'total_spend': 'ì´ ì§€ì¶œ', 'total_revenue': 'ì´ ìˆ˜ìµ', 'total_installs': 'ì´ ì„¤ì¹˜ ìˆ˜'
        })
        
        st.dataframe(
            channel_detail_display[['OS', 'êµ­ê°€', 'ì±„ë„', 'ROAS', 'CPI', 'Profit', 'ì´ ìˆ˜ìµ', 'ì´ ì§€ì¶œ', 'ì´ ì„¤ì¹˜ ìˆ˜']]
            .style.format({
                "ì´ ì§€ì¶œ": "{:,.0f}ì›",
                "ì´ ìˆ˜ìµ": "{:,.0f}ì›",
                "ì´ ì„¤ì¹˜ ìˆ˜": "{:,.0f}",
                "ROAS": "{:.2%}",
                "CPI": "{:,.0f}ì›",
                "Profit": "{:,.0f}ì›"
            }),
            use_container_width=True
        )

def render_main_charts(all_df, final_df, _config, _scenario_template):
    st.subheader("ğŸ“Š ì‹¬ì¸µ ë¶„ì„ ì°¨íŠ¸")
    
    # ê¸°ì¡´ ì°¨íŠ¸ë“¤ (ì²« ë²ˆì§¸ í–‰)
    chart_col1, chart_col2 = st.columns(2)
    with chart_col1:
        st.plotly_chart(create_roas_distribution_figure(final_df), use_container_width=True)
        config_str = json.dumps(convert_numpy_to_native(_config), sort_keys=True)
        scenario_str = json.dumps(convert_numpy_to_native(_scenario_template), sort_keys=True)
        sensitivity_df = run_cached_sensitivity_analysis(config_str, scenario_str)
        st.plotly_chart(create_sensitivity_figure(sensitivity_df), use_container_width=True)
    with chart_col2:
        st.plotly_chart(create_timeseries_figure(all_df), use_container_width=True)
        st.plotly_chart(create_profit_cdf_figure(final_df), use_container_width=True)
    
    # ìƒˆë¡œ ì¶”ê°€ë˜ëŠ” ì°¨íŠ¸ë“¤ (ë‘ ë²ˆì§¸ í–‰)
    st.subheader("ğŸ“ˆ ì±„ë„ ì„±ê³¼ ë¶„ì„")
    analysis_col1, analysis_col2 = st.columns(2)
    with analysis_col1:
        st.plotly_chart(create_cost_efficiency_analysis(all_df), use_container_width=True)
    with analysis_col2:
        st.plotly_chart(create_performance_contribution_analysis(all_df), use_container_width=True)
    
    # ê¸°ì¡´ ë¦¬í…ì…˜ ì°¨íŠ¸
    sim_viz = AdvancedLaunchSimulator(_config['project_info'], _config['assumptions'], 1, _scenario_template, {})
    retention_details = sim_viz.get_retention_model_details()
    st.plotly_chart(create_retention_curve_figure(retention_details), use_container_width=True)
    
    # ê¸°ì¡´ ë¶„í¬ ë¶„ì„
    st.divider()
    st.subheader("ğŸ“Š ë¶„í¬ ë¶„ì„")
    dist_col1, dist_col2 = st.columns(2)
    with dist_col1:
        st.plotly_chart(create_profit_histogram(final_df), use_container_width=True)
    with dist_col2:
        st.plotly_chart(create_profit_kde_plot(final_df), use_container_width=True)


# --- Authentication ---
try:
    with open('auth.yaml') as file:
        auth_config = yaml.safe_load(file)
    authenticator = stauth.Authenticate(
        auth_config['credentials'], auth_config['cookie']['name'],
        auth_config['cookie']['key'], auth_config['cookie']['expiry_days']
    )
    authenticator.login()
except (FileNotFoundError, yaml.YAMLError) as e:
    st.error(f"ì¸ì¦ íŒŒì¼('auth.yaml') ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.stop()

if not st.session_state.get("authentication_status"):
    if st.session_state.get("authentication_status") is False: st.error('ì•„ì´ë”” ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.')
    elif st.session_state.get("authentication_status") is None: st.warning('ì•„ì´ë””ì™€ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.')
    st.stop()

# --- Main App Layout ---
st.sidebar.title(f"í™˜ì˜í•©ë‹ˆë‹¤, *{st.session_state['name']}* ë‹˜")
authenticator.logout('ë¡œê·¸ì•„ì›ƒ', 'sidebar')
st.sidebar.divider()

st.sidebar.title("ë©”ë‰´")
# ì¶”ê°€: ìºì‹œ ê°•ì œ ì´ˆê¸°í™” ë²„íŠ¼ (ë””ë²„ê¹…ìš©)
if st.sidebar.button("ğŸ”„ ìºì‹œ ì´ˆê¸°í™”"):
    st.cache_data.clear()
    st.session_state.simulation_results.clear()
    st.success("ìºì‹œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
page_options = ["ğŸ“Š ëŒ€ì‹œë³´ë“œ & ê²°ê³¼", "âš™ï¸ ì‹œë‚˜ë¦¬ì˜¤ ì—ë””í„°", "ğŸ” ëª¨ë¸ ì‹ ë¢°ë„ í‰ê°€"]
st.session_state.page = st.sidebar.radio("í˜ì´ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”", page_options, label_visibility="collapsed")

st.title("ğŸ“ˆ ë™ì  ë¯¸ë””ì–´ë¯¹ìŠ¤ ì‹œë®¬ë ˆì´í„° (v9.0 - Final)")

# --- Page Content ---
if st.session_state.page == "ğŸ“Š ëŒ€ì‹œë³´ë“œ & ê²°ê³¼":
    selected_arppu_scenario = st.session_state.get('arppu_choice', 'ARPPU D30 (ê¸°ì¤€)')
    st.header(f"ğŸ“Š ëŒ€ì‹œë³´ë“œ & ê²°ê³¼: {selected_arppu_scenario}")
    
    if st.button("ğŸš€ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰", type="primary", key="run_sim_main"):
        with st.spinner(f"'{selected_arppu_scenario}' ì‹œë‚˜ë¦¬ì˜¤ë¡œ ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰í•©ë‹ˆë‹¤..."):
            current_scenario_template = {
                'media_mix': reconstruct_scenario_from_df(st.session_state.media_mix_df.copy(), 'media_mix'),
                'organic_assumptions': reconstruct_scenario_from_df(st.session_state.organic_df.copy(), 'organic')
            }
            
            parts = selected_arppu_scenario.split(" ")
            day_part = parts[1].lower() if len(parts) > 1 else "d30"
            uplift_config_key = f"{day_part}_uplift"

            arppu_params = {
                'scenario': selected_arppu_scenario,
                'uplift_rate': st.session_state.assumptions['arppu_scenario_weights'].get(uplift_config_key, 1.0),
            }
            
            # ì„¤ì • í•´ì‹œ ìƒì„±
            settings_hash = create_settings_hash(
                st.session_state.project_info,
                st.session_state.assumptions, 
                current_scenario_template,
                arppu_params
            )
            
            # í•´ì‹œë¥¼ í¬í•¨í•œ ìºì‹±ëœ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
            all_df, final_df = run_cached_simulation(
                settings_hash,
                st.session_state.project_info,
                st.session_state.assumptions,
                st.session_state.assumptions['monte_carlo']['num_simulations'],
                current_scenario_template,
                arppu_params
            )
            
            st.session_state.simulation_results[selected_arppu_scenario] = {
                "all_df": all_df, 
                "final_df": final_df, 
                "scenario_used": current_scenario_template,
                "settings_hash": settings_hash  # í•´ì‹œê°’ë„ ì €ì¥
            }
            
        st.success(f"'{selected_arppu_scenario}' ì‹œë®¬ë ˆì´ì…˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    if selected_arppu_scenario in st.session_state.simulation_results:
        results = st.session_state.simulation_results[selected_arppu_scenario]
        
        with st.container(border=True):
            render_dashboard_summary(results['final_df'], st.session_state.project_info, st.session_state.assumptions)
        
        st.divider()
        
        with st.container(border=True):
            render_detailed_metrics(results['final_df'])
        
        st.divider()

        with st.container(border=True):
            render_breakdown_tables(results['all_df']) # NEW: Breakdown tables
        
        st.divider()

        with st.container(border=True):
            current_config_for_viz = {
                'project_info': st.session_state.project_info,
                'assumptions': st.session_state.assumptions
            }
            render_main_charts(results['all_df'], results['final_df'], current_config_for_viz, results['scenario_used'])
        
        st.divider()

        with st.container(border=True):
            st.subheader("â¬‡ï¸ ì˜ˆì¸¡ ë°ì´í„° ë‚´ë³´ë‚´ê¸°")
            dl_col1, dl_col2 = st.columns(2)
            with dl_col1:
                export_df = results['all_df'].groupby(['day', 'os', 'country', 'name', 'product', 'type']).median().reset_index()
                st.download_button(label="ì¼ë³„ ìš”ì•½ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", data=export_df.to_csv(index=False).encode('utf-8-sig'), file_name=f"daily_summary_{selected_arppu_scenario}.csv", mime="text/csv")
            with dl_col2:
                st.download_button(label="ì‹œë®¬ë ˆì´ì…˜ Raw ë°ì´í„° ë‹¤ìš´ë¡œë“œ", data=results['final_df'].to_csv(index=False).encode('utf-8-sig'), file_name=f"final_results_{selected_arppu_scenario}.csv", mime="text/csv")

    else:
        st.info("'ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

elif st.session_state.page == "âš™ï¸ ì‹œë‚˜ë¦¬ì˜¤ ì—ë””í„°":
    st.header("âš™ï¸ ì‹œë‚˜ë¦¬ì˜¤ ì—ë””í„°")
    with st.expander("ğŸ“ ì‹œë‚˜ë¦¬ì˜¤ ê´€ë¦¬", expanded=True):
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("í˜„ì¬ ì‹œë‚˜ë¦¬ì˜¤ ì €ì¥")
            new_scenario_name = st.text_input("ì‹œë‚˜ë¦¬ì˜¤ ì´ë¦„", placeholder="ì˜ˆ: 4ë¶„ê¸° ê³µê²©ì  ë§ˆì¼€íŒ…ì•ˆ")
            if st.button("ğŸ’¾ ì‹œë‚˜ë¦¬ì˜¤ ì €ì¥"):
                save_scenario(new_scenario_name, st.session_state.media_mix_df, st.session_state.organic_df)
        with col2:
            st.subheader("ì €ì¥ëœ ì‹œë‚˜ë¦¬ì˜¤ ë¶ˆëŸ¬ì˜¤ê¸°")
            if not st.session_state.scenario_files:
                st.caption("ì €ì¥ëœ ì‹œë‚˜ë¦¬ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                scenario_options = [""] + st.session_state.scenario_files
                selected_scenario = st.selectbox("ë¶ˆëŸ¬ì˜¬ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì„ íƒí•˜ì„¸ìš”", options=scenario_options)
                if st.button("ğŸ“‚ ì‹œë‚˜ë¦¬ì˜¤ ë¶ˆëŸ¬ì˜¤ê¸°"):
                    if selected_scenario:
                        filepath = os.path.join(SCENARIOS_DIR, f"{selected_scenario}.yaml")
                        try:
                            with open(filepath, "r", encoding="utf-8") as f:
                                scenario_data = yaml.safe_load(f)
                            
                            media_df = flatten_scenario_df(scenario_data, 'media_mix')
                            media_df.drop(columns=[col for col in media_df.columns if 'retention' in col and 'scale' in col], inplace=True, errors='ignore')
                            st.session_state.media_mix_df = media_df

                            organic_df = flatten_scenario_from_df(scenario_data, 'organic')
                            organic_df.drop(columns=[col for col in organic_df.columns if 'retention' in col and 'scale' in col], inplace=True, errors='ignore')
                            st.session_state.organic_df = organic_df
                            
                            st.success(f"'{selected_scenario}' ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
                            st.rerun()
                        except (IOError, yaml.YAMLError) as e:
                            st.error(f"'{selected_scenario}' ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    else:
                        st.warning("ë¶ˆëŸ¬ì˜¬ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
    st.subheader("1. ARPPU ì‹œë‚˜ë¦¬ì˜¤")
    st.session_state.arppu_choice = st.radio(
        "ë¶„ì„í•  ARPPU ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
        ('ARPPU D30 (ê¸°ì¤€)', 'ARPPU D60', 'ARPPU D90'),
        horizontal=True, key='arppu_radio'
    )
    st.divider()
    with st.expander("2. í”„ë¡œì íŠ¸ ì •ë³´"):
        p_info = st.session_state.project_info
        p_info['name'] = st.text_input("í”„ë¡œì íŠ¸ ì´ë¦„", value=p_info.get('name', ''))
        
        row1_col1, row1_col2 = st.columns(2)
        with row1_col1:
            p_info['marketing_duration_days'] = st.number_input(
                "ë§ˆì¼€íŒ… ê¸°ê°„ (ì¼)", 
                min_value=1, 
                max_value=365, 
                value=p_info.get('marketing_duration_days', 90),
                help="ê´‘ê³ ë¹„ë¥¼ ì§‘í–‰í•˜ì—¬ ì‹ ê·œ ìœ ì €ë¥¼ íšë“í•˜ëŠ” ê¸°ê°„ì…ë‹ˆë‹¤."
            )
        with row1_col2:
            p_info['ltv_duration_days'] = st.number_input(
                "ëˆ„ì  ë§¤ì¶œ í™•ì¸ ê¸°ê°„ (ì¼)", 
                min_value=p_info['marketing_duration_days'], 
                max_value=730, 
                value=max(p_info.get('ltv_duration_days', 180), p_info['marketing_duration_days']),
                help="ë§ˆì¼€íŒ…ìœ¼ë¡œ ìœ ì…ëœ ìœ ì €ë“¤ì˜ ëˆ„ì  ë§¤ì¶œ(LTV)ì„ ì¶”ì í•˜ëŠ” ì „ì²´ ì‹œë®¬ë ˆì´ì…˜ ê¸°ê°„ì…ë‹ˆë‹¤."
            )

        row2_col1, row2_col2 = st.columns(2)
        with row2_col1:
            p_info['target_budget'] = st.number_input("ì´ ê´‘ê³  ì˜ˆì‚° (ì›)", 1000000, None, p_info.get('target_budget', 1000000000), 1000000)
        with row2_col2:
            p_info['target_roas'] = row2_col2.number_input("ëª©í‘œ ROAS (%)", 1.0, None, p_info.get('target_roas', 1.2) * 100, 1.0) / 100.0

    with st.expander("3. ê³ ê¸‰ ì‹œë®¬ë ˆì´ì…˜ ì„¤ì •"):
        assump = st.session_state.assumptions
        st.markdown("##### ì˜ˆì‚° ì§‘í–‰ íŒ¨í„´")
        ac1, ac2 = st.columns(2)
        assump['budget_pacing']['burst_days'] = ac1.slider("ì´ˆë°˜ ì§‘ì¤‘ ê¸°ê°„ (ì¼)", 1, 90, assump['budget_pacing'].get('burst_days', 30))
        assump['budget_pacing']['burst_intensity'] = ac2.slider("ì§‘ì¤‘ ê¸°ê°„ ê°•ë„ (ë°°ìˆ˜)", 1.0, 5.0, assump['budget_pacing'].get('burst_intensity', 2.5), 0.1)
        st.markdown("##### ê´‘ê³  íš¨ê³¼ ëª¨ë¸ë§")
        ac3, ac4 = st.columns(2)
        assump['adstock']['decay_rate'] = ac3.slider("íš¨ê³¼ ì´ì›” ê³„ìˆ˜", 0.0, 1.0, assump['adstock'].get('decay_rate', 0.5), 0.05)
        assump['adstock']['saturation_alpha'] = ac4.slider("íš¨ê³¼ í¬í™” ê³„ìˆ˜", 0.1, 1.0, assump['adstock'].get('saturation_alpha', 0.8), 0.05)
        st.markdown("##### ì‹œë®¬ë ˆì´ì…˜ ì •ë°€ë„")
        assump['monte_carlo']['num_simulations'] = st.selectbox("ìƒ˜í”Œë§ íšŸìˆ˜", [100, 300, 500, 1000, 2000], index=3)
    
    # --- Add Forms ---
    def render_add_channel_form():
        with st.form(key="add_channel_form"):
            # ... (form content remains the same)
            st.subheader("ğŸ“¢ ìƒˆë¡œìš´ ìœ ë£Œ ì±„ë„ ì¶”ê°€")
            default_paid = st.session_state.config['default_rows']['paid']
            st.markdown("<h6>ì±„ë„ ì •ë³´</h6>", unsafe_allow_html=True)
            c1, c2, c3 = st.columns(3)
            os_val = c1.selectbox("OS", ["iOS", "Android"], index=0)
            country_val = c2.text_input("êµ­ê°€", default_paid['country'])
            name_val = c3.text_input("ì±„ë„ëª…", default_paid['name'])
            c4, c5, c6 = st.columns(3)
            product_val = c4.text_input("ìƒí’ˆ", default_paid['product'])
            type_val = c5.text_input("íƒ€ì…", default_paid['type'])
            budget_val = c6.number_input("ì˜ˆì‚° (ì ˆëŒ€ê°’)", value=100000)
            st.markdown("<h6>ì„±ê³¼ ì§€í‘œ</h6>", unsafe_allow_html=True)
            m1, m2, m3 = st.columns(3)
            with m1:
                st.markdown("**CPI**")
                cpi_loc_val = st.number_input("í‰ê· ", value=default_paid['cpi']['loc'], key="cpi_loc")
                cpi_scale_val = st.number_input("í‘œì¤€í¸ì°¨", value=default_paid['cpi']['scale'], key="cpi_scale")
            with m2:
                st.markdown("**ê²°ì œ ì „í™˜ìœ¨**")
                pcr_a_val = st.number_input("ì„±ê³µ (a)", value=default_paid['payer_conversion_rate']['a'], key="pcr_a")
                pcr_b_val = st.number_input("ì‹¤íŒ¨ (b)", value=default_paid['payer_conversion_rate']['b'], key="pcr_b")
            with m3:
                st.markdown("**ARPPU D30**")
                arppu_loc_val = st.number_input("í‰ê· ", value=default_paid['arppu_d30']['loc'], key="arppu_loc")
                arppu_scale_val = st.number_input("í‘œì¤€í¸ì°¨", value=default_paid['arppu_d30']['scale'], key="arppu_scale")
            st.markdown("<h6>ë¦¬í…ì…˜ ì§€í‘œ (í‰ê· ê°’ë§Œ ì…ë ¥)</h6>", unsafe_allow_html=True)
            r1, r2, r3, r4 = st.columns(4)
            ret_d1_loc = r1.number_input("D1", value=default_paid['retention_d1']['loc'], key="d1_loc", format="%.4f")
            ret_d7_loc = r2.number_input("D7", value=default_paid['retention_d7']['loc'], key="d7_loc", format="%.4f")
            ret_d14_loc = r3.number_input("D14", value=default_paid['retention_d14']['loc'], key="d14_loc", format="%.4f")
            ret_d30_loc = r4.number_input("D30", value=default_paid['retention_d30']['loc'], key="d30_loc", format="%.4f")
            
            submitted = st.form_submit_button("ì±„ë„ ì¶”ê°€")
            if submitted:
                new_row_data = copy.deepcopy(default_paid)
                new_row_data.update({'os': os_val, 'country': country_val, 'name': name_val, 'product': product_val, 'type': type_val, 'budget_ratio': budget_val})
                new_row_data['cpi'] = {'loc': cpi_loc_val, 'scale': cpi_scale_val}
                new_row_data['payer_conversion_rate'] = {'a': pcr_a_val, 'b': pcr_b_val}
                new_row_data['arppu_d30'] = {'loc': arppu_loc_val, 'scale': arppu_scale_val}
                new_row_data['retention_d1'] = {'loc': ret_d1_loc}
                new_row_data['retention_d7'] = {'loc': ret_d7_loc}
                new_row_data['retention_d14'] = {'loc': ret_d14_loc}
                new_row_data['retention_d30'] = {'loc': ret_d30_loc}
                temp_scenario = {'media_mix': [{'os': os_val, 'channels': [{'country': country_val, 'media': [new_row_data]}]}]}
                flat_row = flatten_scenario_df(temp_scenario, 'media_mix')
                flat_row.drop(columns=[col for col in flat_row.columns if 'retention' in col and 'scale' in col], inplace=True, errors='ignore')
                st.session_state.media_mix_df = pd.concat([st.session_state.media_mix_df, flat_row], ignore_index=True)
                st.session_state.show_add_channel_form = False
                st.rerun()

    if st.session_state.show_add_channel_form:
        render_add_channel_form()

    with st.expander("4. ìœ ë£Œ ì±„ë„ ë¯¹ìŠ¤", expanded=not st.session_state.show_add_channel_form):
        st.subheader("ì±„ë„ ì¶”ê°€ ë°©ì‹ ì„ íƒ")
        if st.button("ğŸ“¢ ê°œë³„ ì±„ë„ ì¶”ê°€", key="add_paid_channel_btn"):
            st.session_state.show_add_channel_form = True
            st.rerun()
        
        st.markdown("---")
        st.subheader("CSV ì¼ê´„ ì—…ë¡œë“œ")
        
        col1, col2 = st.columns(2)
        with col1:
            media_mix_template_df = pd.DataFrame(columns=st.session_state.media_mix_df.columns)
            st.download_button(
                label="ğŸ“¦ CSV í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ",
                data=media_mix_template_df.to_csv(index=False).encode('utf-8-sig'),
                file_name='paid_channel_template.csv',
                mime='text/csv',
            )
        with col2:
            uploaded_media_mix_file = st.file_uploader("ğŸ“‚ CSV íŒŒì¼ ì—…ë¡œë“œ", type="csv", key="media_mix_uploader")

        if uploaded_media_mix_file is not None:
            try:
                new_media_mix_df = pd.read_csv(uploaded_media_mix_file)
                if list(new_media_mix_df.columns) == list(st.session_state.media_mix_df.columns):
                    st.session_state.media_mix_df = pd.concat(
                        [st.session_state.media_mix_df, new_media_mix_df],
                        ignore_index=True
                    )
                    st.success("ìœ ë£Œ ì±„ë„ ëª©ë¡ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!")
                else:
                    st.error("CSV íŒŒì¼ì˜ ì»¬ëŸ¼ì´ ê¸°ì¡´ í…œí”Œë¦¿ê³¼ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

        st.markdown("---")
        st.subheader("í™•ì • ì±„ë„ ë¦¬ìŠ¤íŠ¸")
        st.caption("í‘œì˜ ì…€ì„ ë”ë¸”í´ë¦­í•˜ì—¬ ì§ì ‘ ìˆ˜ì •í•˜ê±°ë‚˜, í–‰ì„ ì„ íƒí•˜ê³  ì‚­ì œ ì•„ì´ì½˜ì„ ëˆŒëŸ¬ ì œê±°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. '+' ë²„íŠ¼ìœ¼ë¡œ ìƒˆ í–‰ì„ ì¶”ê°€í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.")
        edited_media_df = st.data_editor(
            st.session_state.media_mix_df,
            num_rows="dynamic",
            use_container_width=True,
            key="media_mix_editor"
        )
        st.session_state.media_mix_df = edited_media_df

        st.download_button(label="í˜„ì¬ ëª©ë¡ CSVë¡œ ë‚´ë³´ë‚´ê¸°", data=st.session_state.media_mix_df.to_csv(index=False).encode('utf-8-sig'), file_name='media_mix.csv', mime='text/csv')

    st.divider()

    def render_add_organic_form():
        with st.form(key="add_organic_form"):
            # ... (form content remains the same)
            st.subheader("ğŸŒ± ìƒˆë¡œìš´ ìì—° ìœ ì… êµ­ê°€ ì¶”ê°€")
            default_org = st.session_state.config['default_rows']['organic']
            country_val = st.text_input("êµ­ê°€", default_org['country'])
            st.markdown("<h6>ì„±ê³¼ ì§€í‘œ</h6>", unsafe_allow_html=True)
            m1, m2, m3 = st.columns(3)
            with m1:
                st.markdown("**ì¼ë³„ ì„¤ì¹˜ ìˆ˜**")
                installs_loc_val = st.number_input("í‰ê· ", value=default_org['daily_installs']['loc'], key="org_inst_loc")
                installs_scale_val = st.number_input("í‘œì¤€í¸ì°¨", value=default_org['daily_installs']['scale'], key="org_inst_scale")
            with m2:
                st.markdown("**ê²°ì œ ì „í™˜ìœ¨**")
                pcr_a_val = st.number_input("ì„±ê³µ (a)", value=default_org['payer_conversion_rate']['a'], key="org_pcr_a")
                pcr_b_val = st.number_input("ì‹¤íŒ¨ (b)", value=default_org['payer_conversion_rate']['b'], key="org_pcr_b")
            with m3:
                st.markdown("**ARPPU D30**")
                arppu_loc_val = st.number_input("í‰ê· ", value=default_org['arppu_d30']['loc'], key="org_arppu_loc")
                arppu_scale_val = st.number_input("í‘œì¤€í¸ì°¨", value=default_org['arppu_d30']['scale'], key="org_arppu_scale")
            st.markdown("<h6>ë¦¬í…ì…˜ ì§€í‘œ (í‰ê· ê°’ë§Œ ì…ë ¥)</h6>", unsafe_allow_html=True)
            r1, r2, r3, r4 = st.columns(4)
            ret_d1_loc = r1.number_input("D1", value=default_org['retention_d1']['loc'], key="org_d1_loc", format="%.4f")
            ret_d7_loc = r2.number_input("D7", value=default_org['retention_d7']['loc'], key="org_d7_loc", format="%.4f")
            ret_d14_loc = r3.number_input("D14", value=default_org['retention_d14']['loc'], key="d14_loc", format="%.4f")
            ret_d30_loc = r4.number_input("D30", value=default_org['retention_d30']['loc'], key="d30_loc", format="%.4f")
                
            submitted = st.form_submit_button("êµ­ê°€ ì¶”ê°€")
            if submitted:
                new_row_data = copy.deepcopy(default_org)
                new_row_data['country'] = country_val
                new_row_data['daily_installs'] = {'loc': installs_loc_val, 'scale': installs_scale_val}
                new_row_data['payer_conversion_rate'] = {'a': pcr_a_val, 'b': pcr_b_val}
                new_row_data['arppu_d30'] = {'loc': arppu_loc_val, 'scale': arppu_scale_val}
                new_row_data['retention_d1'] = {'loc': ret_d1_loc}
                new_row_data['retention_d7'] = {'loc': ret_d7_loc}
                new_row_data['retention_d14'] = {'loc': ret_d14_loc}
                new_row_data['retention_d30'] = {'loc': ret_d30_loc}
                flat_row = flatten_scenario_df({'organic_assumptions': [new_row_data]}, 'organic')
                flat_row.drop(columns=[col for col in flat_row.columns if 'retention' in col and 'scale' in col], inplace=True, errors='ignore')
                st.session_state.organic_df = pd.concat([st.session_state.organic_df, flat_row], ignore_index=True)
                st.session_state.show_add_organic_form = False
                st.rerun()
    
    if st.session_state.show_add_organic_form:
        render_add_organic_form()

    with st.expander("5. ìì—° ìœ ì… ì„¤ì •", expanded=not st.session_state.show_add_organic_form):
        st.subheader("êµ­ê°€ ì¶”ê°€ ë°©ì‹ ì„ íƒ")
        if st.button("ğŸŒ± ê°œë³„ êµ­ê°€ ì¶”ê°€", key="add_organic_country_btn"):
            st.session_state.show_add_organic_form = True
            st.rerun()
        
        st.markdown("---")
        st.subheader("CSV ì¼ê´„ ì—…ë¡œë“œ")

        col1, col2 = st.columns(2)
        with col1:
            organic_template_df = pd.DataFrame(columns=st.session_state.organic_df.columns)
            st.download_button(
                label="ğŸ“¦ CSV í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ",
                data=organic_template_df.to_csv(index=False).encode('utf-8-sig'),
                file_name='organic_inflow_template.csv',
                mime='text/csv',
            )
        with col2:
            uploaded_organic_file = st.file_uploader("ğŸ“‚ CSV íŒŒì¼ ì—…ë¡œë“œ", type="csv", key="organic_uploader")
        
        if uploaded_organic_file is not None:
            try:
                new_organic_df = pd.read_csv(uploaded_organic_file)
                if list(new_organic_df.columns) == list(st.session_state.organic_df.columns):
                    st.session_state.organic_df = pd.concat(
                        [st.session_state.organic_df, new_organic_df],
                        ignore_index=True
                    )
                    st.success("ìì—° ìœ ì… êµ­ê°€ ëª©ë¡ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!")
                else:
                    st.error("CSV íŒŒì¼ì˜ ì»¬ëŸ¼ì´ ê¸°ì¡´ í…œí”Œë¦¿ê³¼ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

        st.markdown("---")
        st.subheader("í™•ì • êµ­ê°€ ë¦¬ìŠ¤íŠ¸")
        st.caption("í‘œì˜ ì…€ì„ ë”ë¸”í´ë¦­í•˜ì—¬ ì§ì ‘ ìˆ˜ì •í•˜ê±°ë‚˜, í–‰ì„ ì„ íƒí•˜ê³  ì‚­ì œ ì•„ì´ì½˜ì„ ëˆŒëŸ¬ ì œê±°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        edited_organic_df = st.data_editor(
            st.session_state.organic_df,
            num_rows="dynamic",
            use_container_width=True,
            key="organic_editor"
        )
        st.session_state.organic_df = edited_organic_df

    # [FIX] Logic to clear results if settings have changed
    current_scenario_template_for_check = {
        'media_mix': reconstruct_scenario_from_df(st.session_state.media_mix_df.copy(), 'media_mix'),
        'organic_assumptions': reconstruct_scenario_from_df(st.session_state.organic_df.copy(), 'organic')
    }
    current_settings_for_check = {
        "project_info": st.session_state.project_info,
        "assumptions": st.session_state.assumptions,
        "scenario_template": current_scenario_template_for_check,
        "arppu_choice": st.session_state.arppu_choice
    }
    current_signature = json.dumps(current_settings_for_check, default=convert_numpy_to_native, sort_keys=True)
    
    if st.session_state.last_run_settings_signature and current_signature != st.session_state.last_run_settings_signature:
        st.session_state.simulation_results.clear()
        st.session_state.last_run_settings_signature = None
        st.toast("âš™ï¸ ì„¤ì •ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤. ëŒ€ì‹œë³´ë“œì—ì„œ ì‹œë®¬ë ˆì´ì…˜ì„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")


elif st.session_state.page == "ğŸ” ëª¨ë¸ ì‹ ë¢°ë„ í‰ê°€":
    st.header("ğŸ” ëª¨ë¸ ì‹ ë¢°ë„ í‰ê°€")
    st.subheader("1. ìˆ˜ë ´ í…ŒìŠ¤íŠ¸")
    st.info("ì‹œë®¬ë ˆì´ì…˜ íšŸìˆ˜ë¥¼ ëŠ˜ë ¤ê°ì— ë”°ë¼ ê²°ê³¼ê°’ì´ ì•ˆì •ì ìœ¼ë¡œ ìˆ˜ë ´í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.")
    if st.button("ìˆ˜ë ´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"):
        with st.spinner("ìˆ˜ë ´ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
            convergence_scenario = {
                'media_mix': reconstruct_scenario_from_df(st.session_state.media_mix_df.copy(), 'media_mix'),
                'organic_assumptions': reconstruct_scenario_from_df(st.session_state.organic_df.copy(), 'organic')
            }
            
            sim = AdvancedLaunchSimulator(st.session_state.project_info, st.session_state.assumptions, st.session_state.assumptions['monte_carlo']['num_simulations'], convergence_scenario, {'scenario': 'ARPPU D30 (ê¸°ì¤€)', 'uplift_rate': 1.0})
            convergence_data = sim.run_convergence_test()
            st.plotly_chart(create_convergence_figure(convergence_data), use_container_width=True)
    st.divider()
    st.subheader("2. ë°±í…ŒìŠ¤íŒ…")
    st.info("ê³¼ê±° ì‹¤ì œ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì—¬, í˜„ì¬ ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì •ì´ ê³¼ê±° ì„±ê³¼ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ì„¤ëª…í•˜ëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤.")
    uploaded_file = st.file_uploader("ê³¼ê±° ì„±ê³¼ ë°ì´í„° ì—…ë¡œë“œ (CSV)", type="csv")
    if uploaded_file:
        try:
            actual_data = pd.read_csv(uploaded_file)
            required_cols = ['day', 'actual_roas']
            if all(col in actual_data.columns for col in required_cols):
                actual_data = actual_data[required_cols].astype({'day': 'int', 'actual_roas': 'float'})
                st.dataframe(actual_data.head())
                if st.button("ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰"):
                    with st.spinner("ë°±í…ŒìŠ¤íŒ… ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
                        backtest_scenario = {
                            'media_mix': reconstruct_scenario_from_df(st.session_state.media_mix_df.copy(), 'media_mix'),
                            'organic_assumptions': reconstruct_scenario_from_df(st.session_state.organic_df.copy(), 'organic')
                        }
                        
                        settings_for_backtest = {
                            "project_info": st.session_state.project_info,
                            "assumptions": st.session_state.assumptions,
                            "num_simulations": 300, # Using a fixed number for backtesting
                            "scenario_template": backtest_scenario,
                            "arppu_params": {'scenario': 'ARPPU D30 (ê¸°ì¤€)', 'uplift_rate': 1.0}
                        }
                        backtest_signature = json.dumps(settings_for_backtest, default=convert_numpy_to_native, sort_keys=True)
                        all_df_backtest, _ = run_cached_simulation(backtest_signature)
                        
                        sim_median_roas = all_df_backtest.groupby('day')['paid_roas'].median().reset_index().rename(columns={'paid_roas': 'predicted_roas'})
                        comparison_df = pd.merge(actual_data, sim_median_roas, on='day', how='left').dropna()
                        rmse, mape = calculate_errors(comparison_df['actual_roas'], comparison_df['predicted_roas'])
                        st.plotly_chart(create_backtesting_figure(all_df_backtest, actual_data), use_container_width=True)
                        c1, c2 = st.columns(2)
                        c1.metric("RMSE", f"{rmse:.4f}")
                        c2.metric("MAPE", f"{mape:.2f}%")
            else:
                st.error(f"CSV íŒŒì¼ì— ë‹¤ìŒ í•„ìˆ˜ ì»¬ëŸ¼ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤: {', '.join(required_cols)}")
        except Exception as e:
            st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

