import streamlit as st
import pandas as pd
import numpy as np
import copy
import yaml
import streamlit_authenticator as stauth
import os
from scipy.stats import weibull_min

# [FIX] Import helper functions from the new utils.py file
from utils import (
    load_config, format_number, calculate_errors,
    flatten_scenario_df, reconstruct_scenario_from_df
)
from advanced_simulator import AdvancedLaunchSimulator
from analysis import StrategicAnalyzer
from visualization import (
    create_roas_distribution_figure, create_timeseries_figure, create_retention_curve_figure,
    create_sensitivity_figure, create_profit_cdf_figure, create_convergence_figure,
    create_backtesting_figure, create_profit_histogram, create_profit_kde_plot
)

# --- Constants ---
# [UPDATE] Changed to a directory for individual scenario files
SCENARIOS_DIR = "scenarios"

# --- Caching Functions ---
@st.cache_data
def run_cached_simulation(_project_info, _assumptions, _num_simulations, _scenario_template, _arppu_params):
    """Runs a cached Monte Carlo simulation."""
    progress_bar = st.progress(0, text="ì‹œë®¬ë ˆì´ì…˜ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤...")
    def update_progress(progress, text):
        progress_bar.progress(progress, text=text)

    simulator = AdvancedLaunchSimulator(_project_info, _assumptions, _num_simulations, _scenario_template, _arppu_params)
    results = simulator.run_monte_carlo(progress_callback=update_progress)
    progress_bar.empty()
    return results

@st.cache_data
def run_cached_sensitivity_analysis(_config, _scenario_data):
    """Runs a cached sensitivity analysis."""
    analyzer = StrategicAnalyzer(_config)
    return analyzer.run_sensitivity_analysis(_scenario_data)

# --- Scenario Management Functions ---
def load_scenario_names():
    """Loads scenario names by scanning the scenarios directory."""
    if not os.path.exists(SCENARIOS_DIR):
        return []
    try:
        files = [f for f in os.listdir(SCENARIOS_DIR) if f.endswith((".yaml", ".yml"))]
        # Return names without extension, sorted alphabetically
        return sorted([os.path.splitext(f)[0] for f in files])
    except IOError as e:
        st.error(f"ì‹œë‚˜ë¦¬ì˜¤ í´ë”ë¥¼ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

def convert_numpy_to_native(data):
    """Recursively converts numpy types in a dict/list to native Python types for YAML serialization."""
    if isinstance(data, dict):
        return {key: convert_numpy_to_native(value) for key, value in data.items()}
    elif isinstance(data, list):
        return [convert_numpy_to_native(element) for element in data]
    elif isinstance(data, np.integer):
        return int(data)
    elif isinstance(data, np.floating):
        return float(data)
    elif isinstance(data, np.ndarray):
        return data.tolist()
    else:
        return data

def save_scenario(name, media_df, organic_df):
    """Saves the current scenario configuration as a separate .yaml file."""
    if not name:
        st.warning("ì‹œë‚˜ë¦¬ì˜¤ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return

    # Basic sanitization for filename
    sanitized_name = "".join(c for c in name if c.isalnum() or c in (' ', '_', '-')).rstrip()
    if not sanitized_name:
        st.warning("ìœ íš¨í•œ ì‹œë‚˜ë¦¬ì˜¤ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì•ŒíŒŒë²³, ìˆ«ì, ê³µë°±, _, - ë§Œ í—ˆìš©)")
        return
        
    filename = f"{sanitized_name}.yaml"
    filepath = os.path.join(SCENARIOS_DIR, filename)

    # Create the directory if it doesn't exist
    os.makedirs(SCENARIOS_DIR, exist_ok=True)

    scenario_data = {
        'media_mix': reconstruct_scenario_from_df(media_df.copy(), 'media_mix'),
        'organic_assumptions': reconstruct_scenario_from_df(organic_df.copy(), 'organic')
    }

    native_data = convert_numpy_to_native(scenario_data)

    try:
        with open(filepath, "w", encoding="utf-8") as f:
            yaml.dump(native_data, f, allow_unicode=True, sort_keys=False, default_flow_style=False)
        st.success(f"'{name}' ì‹œë‚˜ë¦¬ì˜¤ê°€ '{filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        # Refresh the list of scenarios in the session state
        st.session_state.scenario_files = load_scenario_names()
    except IOError as e:
        st.error(f"ì‹œë‚˜ë¦¬ì˜¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


# --- Page Config ---
st.set_page_config(layout="wide", page_title="ë¯¸ë””ì–´ë¯¹ìŠ¤ ì‹œë®¬ë ˆì´í„°")

# --- Session State Initialization ---
if 'config' not in st.session_state:
    st.session_state.config = load_config()
if 'project_info' not in st.session_state:
    st.session_state.project_info = st.session_state.config['project_info']
if 'assumptions' not in st.session_state:
    st.session_state.assumptions = st.session_state.config['assumptions']
if 'simulation_results' not in st.session_state:
    st.session_state.simulation_results = {}
if 'media_mix_df' not in st.session_state:
    st.session_state.media_mix_df = flatten_scenario_df(st.session_state.config['scenario_template'], 'media_mix')
if 'organic_df' not in st.session_state:
    st.session_state.organic_df = flatten_scenario_df(st.session_state.config['scenario_template'], 'organic')
if 'scenario_files' not in st.session_state:
    st.session_state.scenario_files = load_scenario_names()
if 'show_add_organic_form' not in st.session_state:
    st.session_state.show_add_organic_form = False
if 'show_add_channel_form' not in st.session_state:
    st.session_state.show_add_channel_form = False


# --- UI Rendering Functions ---
def render_dashboard_summary(final_df, project_info, assumptions):
    st.subheader("ğŸ¯ ìµœì¢… ì„±ê³¼ ìš”ì•½")
    col1, col2, col3 = st.columns(3)
    median_roas = final_df['paid_roas'].median()
    median_revenue = final_df['paid_revenue'].median()
    total_budget = project_info['target_budget']
    median_profit = final_df['total_profit'].median()
    median_roi = median_profit / total_budget if total_budget > 0 else 0

    with col1:
        st.metric("ì˜ˆì¸¡ ROAS (ì¤‘ì•™ê°’)", f"{median_roas:.2%}", help="ê´‘ê³ ë¹„ ëŒ€ë¹„ ìœ ë£Œ ì±„ë„ ë§¤ì¶œ")
        st.markdown(f"**ì˜ˆìƒ ìœ ë£Œ ë§¤ì¶œ:** {format_number(median_revenue, True)}")
    with col2:
        st.metric("ì˜ˆì¸¡ ROI (ì¤‘ì•™ê°’)", f"{median_roi:.2%}", help="ê´‘ê³ ë¹„ ëŒ€ë¹„ ì „ì²´ ìˆœìˆ˜ìµ")
        st.markdown(f"**ì˜ˆìƒ ì „ì²´ ìˆœìˆ˜ìµ:** {format_number(median_profit, True)}")
    with col3:
        render_target_guide(final_df, project_info, assumptions)

def render_target_guide(final_df, project_info, assumptions):
    with st.container(border=True):
        st.markdown("##### ğŸ¯ ëª©í‘œ ë‹¬ì„± ê°€ì´ë“œ")
        target_roas = project_info['target_roas']
        st.markdown(f"**ëª©í‘œ ROAS:** `{target_roas:.1%}`")

        # [UPDATE] Calculate all required metrics for the guide
        paid_installs_median = final_df['paid_installs'].median()
        total_installs_median = final_df['total_installs'].median()
        paid_revenue_median = final_df['paid_revenue'].median()
        total_revenue_median = final_df['total_revenue'].median()
        blended_pcr_median = final_df['blended_pcr'].median()
        
        total_budget = project_info['target_budget']
        required_paid_revenue = target_roas * total_budget
        
        # Required Total/Blended CPI
        organic_revenue_median = total_revenue_median - paid_revenue_median
        required_total_revenue = required_paid_revenue + organic_revenue_median
        blended_cpi_median = total_budget / total_installs_median if total_installs_median > 0 else 0
        required_total_cpi = blended_cpi_median * (total_revenue_median / required_total_revenue) if required_total_revenue > 0 and total_revenue_median > 0 else np.nan

        # Required Paid CPI
        paid_cpi_median = total_budget / paid_installs_median if paid_installs_median > 0 else 0
        improvement_factor = required_paid_revenue / paid_revenue_median if paid_revenue_median > 0 else np.nan
        required_paid_cpi = paid_cpi_median / improvement_factor if not np.isnan(improvement_factor) else np.nan
        
        # Required ARPU & ARPPU
        required_total_arpu = required_total_revenue / total_installs_median if total_installs_median > 0 else 0
        total_paying_users_median = total_installs_median * blended_pcr_median
        required_total_arppu = required_total_revenue / total_paying_users_median if total_paying_users_median > 0 else 0

        st.markdown(f"**í•„ìš” Total CPI (ìƒí•œ):** `{format_number(required_total_cpi, True)}`")
        st.markdown(f"**í•„ìš” Paid CPI (ìƒí•œ):** `{format_number(required_paid_cpi, True)}`")
        st.markdown(f"**í•„ìš” ì „ì²´ ARPU:** `{format_number(required_total_arpu, True)}`")
        st.markdown(f"**í•„ìš” ì „ì²´ ARPPU:** `{format_number(required_total_arppu, True)}`")


def render_detailed_metrics(final_df):
    st.subheader("ğŸ“ˆ ìƒì„¸ ì§€í‘œ ë¶„ì„ (ì¤‘ì•™ê°’ ê¸°ì¤€)")
    
    kpi_metrics = {
        "ì´ìˆ˜ìµ": ("total_revenue", True, 0), 
        "ì´ ì„¤ì¹˜ ìˆ˜": ("total_installs", False, 0),
        "ìœ ë£Œ ì„¤ì¹˜ ìˆ˜": ("paid_installs", False, 0),
        "ì „ì²´ CPI": ("blended_cpi", True, 0),
        "ìœ ë£Œ CPI": ("paid_cpi", True, 0),
        "ì „ì²´ ARPU": ("blended_arpu", True, 0),
        "ì „ì²´ ARPPU": ("blended_arppu", True, 0)
    }
    
    # [UPDATE] More dynamic layout generation for metrics
    keys = list(kpi_metrics.keys())
    num_metrics = len(keys)
    num_cols = 4  # Display 4 metrics per row

    for i in range(0, num_metrics, num_cols):
        row_keys = keys[i:i + num_cols]
        # [FIX] Create columns based on the number of items in the current row
        cols = st.columns(len(row_keys))
        for j, key in enumerate(row_keys):
            metric_key, is_currency, dec = kpi_metrics[key]
            with cols[j]:
                if metric_key in final_df.columns:
                    median_val = final_df[metric_key].median()
                    p10, p90 = final_df[metric_key].quantile(0.1), final_df[metric_key].quantile(0.9)
                    st.metric(key, format_number(median_val, is_currency, dec),
                              help=f"P10: {format_number(p10, is_currency, dec)}\nP90: {format_number(p90, is_currency, dec)}")
        # Add vertical space only if it's not the last row
        if i + num_cols < num_metrics:
            st.write("")


def render_main_charts(all_df, final_df, _config, _scenario_template):
    st.subheader("ğŸ” ì‹¬ì¸µ ë¶„ì„ ì°¨íŠ¸")
    chart_col1, chart_col2 = st.columns(2)
    with chart_col1:
        st.plotly_chart(create_roas_distribution_figure(final_df), use_container_width=True)
        analyzer_config = {'project_info': _config['project_info'], 'assumptions': _config['assumptions']}
        sensitivity_df = run_cached_sensitivity_analysis(analyzer_config, _scenario_template)
        st.plotly_chart(create_sensitivity_figure(sensitivity_df), use_container_width=True)
    with chart_col2:
        st.plotly_chart(create_timeseries_figure(all_df), use_container_width=True)
        st.plotly_chart(create_profit_cdf_figure(final_df), use_container_width=True)

    sim_viz = AdvancedLaunchSimulator(_config['project_info'], _config['assumptions'], 1, _scenario_template, {})
    retention_details = sim_viz.get_retention_model_details()
    st.plotly_chart(create_retention_curve_figure(retention_details), use_container_width=True)
    st.divider()
    st.subheader("ğŸ“Š ë¶„í¬ ë¶„ì„")
    dist_col1, dist_col2 = st.columns(2)
    with dist_col1:
        st.plotly_chart(create_profit_histogram(final_df), use_container_width=True)
    with dist_col2:
        st.plotly_chart(create_profit_kde_plot(final_df), use_container_width=True)

# ===================================================================
# 1. User Authentication
# ===================================================================
try:
    with open('auth.yaml') as file:
        auth_config = yaml.safe_load(file)
    authenticator = stauth.Authenticate(
        auth_config['credentials'], auth_config['cookie']['name'],
        auth_config['cookie']['key'], auth_config['cookie']['expiry_days']
    )
    authenticator.login()
except (FileNotFoundError, yaml.YAMLError) as e:
    st.error(f"ì¸ì¦ íŒŒì¼('auth.yaml') ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.stop()

if not st.session_state.get("authentication_status"):
    if st.session_state.get("authentication_status") is False: st.error('ì•„ì´ë”” ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.')
    elif st.session_state.get("authentication_status") is None: st.warning('ì•„ì´ë””ì™€ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.')
    st.stop()

# --- Main App Logic ---
st.sidebar.title(f"í™˜ì˜í•©ë‹ˆë‹¤, *{st.session_state['name']}* ë‹˜")
authenticator.logout('ë¡œê·¸ì•„ì›ƒ', 'sidebar')
st.title("ğŸ“ˆ ë™ì  ë¯¸ë””ì–´ë¯¹ìŠ¤ ì‹œë®¬ë ˆì´í„° (v6.6 - ì§€í‘œ í™•ì¥)")
tab1, tab2, tab3 = st.tabs(["ğŸ“Š ëŒ€ì‹œë³´ë“œ & ê²°ê³¼", "âš™ï¸ ì‹œë‚˜ë¦¬ì˜¤ ì—ë””í„°", "ğŸ” ëª¨ë¸ ì‹ ë¢°ë„ í‰ê°€"])

# =====================================================================================
# Tab 2: Scenario Editor
# =====================================================================================
with tab2:
    st.header("âš™ï¸ ì‹œë‚˜ë¦¬ì˜¤ ì—ë””í„°")

    with st.expander("ğŸ“ ì‹œë‚˜ë¦¬ì˜¤ ê´€ë¦¬", expanded=True):
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("í˜„ì¬ ì‹œë‚˜ë¦¬ì˜¤ ì €ì¥")
            new_scenario_name = st.text_input("ì‹œë‚˜ë¦¬ì˜¤ ì´ë¦„", placeholder="ì˜ˆ: 4ë¶„ê¸° ê³µê²©ì  ë§ˆì¼€íŒ…ì•ˆ")
            if st.button("ğŸ’¾ ì‹œë‚˜ë¦¬ì˜¤ ì €ì¥"):
                save_scenario(new_scenario_name, st.session_state.media_mix_df, st.session_state.organic_df)
        
        with col2:
            st.subheader("ì €ì¥ëœ ì‹œë‚˜ë¦¬ì˜¤ ë¶ˆëŸ¬ì˜¤ê¸°")
            if not st.session_state.scenario_files:
                st.caption("ì €ì¥ëœ ì‹œë‚˜ë¦¬ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                scenario_options = [""] + st.session_state.scenario_files
                selected_scenario = st.selectbox("ë¶ˆëŸ¬ì˜¬ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì„ íƒí•˜ì„¸ìš”", options=scenario_options)
                if st.button("ğŸ“‚ ì‹œë‚˜ë¦¬ì˜¤ ë¶ˆëŸ¬ì˜¤ê¸°"):
                    if selected_scenario:
                        filepath = os.path.join(SCENARIOS_DIR, f"{selected_scenario}.yaml")
                        try:
                            with open(filepath, "r", encoding="utf-8") as f:
                                scenario_data = yaml.safe_load(f)
                            st.session_state.media_mix_df = flatten_scenario_df(scenario_data, 'media_mix')
                            st.session_state.organic_df = flatten_scenario_df(scenario_data, 'organic')
                            st.success(f"'{selected_scenario}' ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
                            st.rerun()
                        except (IOError, yaml.YAMLError) as e:
                            st.error(f"'{selected_scenario}' ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    else:
                        st.warning("ë¶ˆëŸ¬ì˜¬ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
    
    st.subheader("1. ARPPU ì‹œë‚˜ë¦¬ì˜¤")
    st.session_state.arppu_choice = st.radio(
        "ë¶„ì„í•  ARPPU ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
        ('ARPPU D30 (ê¸°ì¤€)', 'ARPPU D60', 'ARPPU D90'),
        horizontal=True, key='arppu_radio'
    )
    st.divider()

    with st.expander("2. í”„ë¡œì íŠ¸ ì •ë³´"):
        p_info = st.session_state.project_info
        p_info['name'] = st.text_input("í”„ë¡œì íŠ¸ ì´ë¦„", value=p_info.get('name', ''))
        pc1, pc2, pc3 = st.columns(3)
        p_info['marketing_duration_days'] = pc1.number_input("ë§ˆì¼€íŒ… ê¸°ê°„ (ì¼)", 30, 365, p_info.get('marketing_duration_days', 180))
        p_info['target_budget'] = pc2.number_input("ì´ ê´‘ê³  ì˜ˆì‚° (ì›)", 1000000, None, p_info.get('target_budget', 1000000000), 1000000)
        p_info['target_roas'] = pc3.number_input("ëª©í‘œ ROAS (%)", 1.0, None, p_info.get('target_roas', 1.2) * 100, 1.0) / 100.0

    with st.expander("3. ê³ ê¸‰ ì‹œë®¬ë ˆì´ì…˜ ì„¤ì •"):
        assump = st.session_state.assumptions
        st.markdown("##### ì˜ˆì‚° ì§‘í–‰ íŒ¨í„´")
        ac1, ac2 = st.columns(2)
        assump['budget_pacing']['burst_days'] = ac1.slider("ì´ˆë°˜ ì§‘ì¤‘ ê¸°ê°„ (ì¼)", 1, 90, assump['budget_pacing'].get('burst_days', 30))
        assump['budget_pacing']['burst_intensity'] = ac2.slider("ì§‘ì¤‘ ê¸°ê°„ ê°•ë„ (ë°°ìˆ˜)", 1.0, 5.0, assump['budget_pacing'].get('burst_intensity', 2.5), 0.1)
        st.markdown("##### ê´‘ê³  íš¨ê³¼ ëª¨ë¸ë§")
        ac3, ac4 = st.columns(2)
        assump['adstock']['decay_rate'] = ac3.slider("íš¨ê³¼ ì´ì›” ê³„ìˆ˜", 0.0, 1.0, assump['adstock'].get('decay_rate', 0.5), 0.05)
        assump['adstock']['saturation_alpha'] = ac4.slider("íš¨ê³¼ í¬í™” ê³„ìˆ˜", 0.1, 1.0, assump['adstock'].get('saturation_alpha', 0.8), 0.05)
        st.markdown("##### ì‹œë®¬ë ˆì´ì…˜ ì •ë°€ë„")
        assump['monte_carlo']['num_simulations'] = st.selectbox("ìƒ˜í”Œë§ íšŸìˆ˜", [100, 300, 500, 1000, 2000], index=3)

    def render_add_channel_form():
        with st.form(key="add_channel_form"):
            st.subheader("ğŸ“¢ ìƒˆë¡œìš´ ìœ ë£Œ ì±„ë„ ì¶”ê°€")
            default_paid = st.session_state.config['default_rows']['paid']
            st.markdown("<h6>ì±„ë„ ì •ë³´</h6>", unsafe_allow_html=True)
            c1, c2, c3 = st.columns(3)
            os_val = c1.selectbox("OS", ["iOS", "Android"], index=0)
            country_val = c2.text_input("êµ­ê°€", default_paid['country'])
            name_val = c3.text_input("ì±„ë„ëª…", default_paid['name'])
            c4, c5, c6 = st.columns(3)
            product_val = c4.text_input("ìƒí’ˆ", default_paid['product'])
            type_val = c5.text_input("íƒ€ì…", default_paid['type'])
            budget_val = c6.number_input("ì˜ˆì‚° (ì ˆëŒ€ê°’)", value=100000)
            st.markdown("<h6>ì„±ê³¼ ì§€í‘œ</h6>", unsafe_allow_html=True)
            m1, m2, m3 = st.columns(3)
            with m1:
                st.markdown("**CPI**")
                cpi_loc_val = st.number_input("í‰ê·  (loc)", value=default_paid['cpi']['loc'], key="cpi_loc")
                cpi_scale_val = st.number_input("í‘œì¤€í¸ì°¨ (scale)", value=default_paid['cpi']['scale'], key="cpi_scale")
            with m2:
                st.markdown("**ê²°ì œ ì „í™˜ìœ¨**")
                pcr_a_val = st.number_input("ì„±ê³µ (a)", value=default_paid['payer_conversion_rate']['a'], key="pcr_a")
                pcr_b_val = st.number_input("ì‹¤íŒ¨ (b)", value=default_paid['payer_conversion_rate']['b'], key="pcr_b")
            with m3:
                st.markdown("**ARPPU D30**")
                arppu_loc_val = st.number_input("í‰ê·  (loc)", value=default_paid['arppu_d30']['loc'], key="arppu_loc")
                arppu_scale_val = st.number_input("í‘œì¤€í¸ì°¨ (scale)", value=default_paid['arppu_d30']['scale'], key="arppu_scale")
            st.markdown("<h6>ë¦¬í…ì…˜ ì§€í‘œ</h6>", unsafe_allow_html=True)
            r1, r2, r3, r4 = st.columns(4)
            with r1:
                st.markdown("**D1**")
                ret_d1_loc = st.number_input("í‰ê· ", value=default_paid['retention_d1']['loc'], key="d1_loc", format="%.4f")
                ret_d1_scale = st.number_input("í‘œì¤€í¸ì°¨", value=default_paid['retention_d1']['scale'], key="d1_scale", format="%.4f")
            with r2:
                st.markdown("**D7**")
                ret_d7_loc = st.number_input("í‰ê· ", value=default_paid['retention_d7']['loc'], key="d7_loc", format="%.4f")
                ret_d7_scale = st.number_input("í‘œì¤€í¸ì°¨", value=default_paid['retention_d7']['scale'], key="d7_scale", format="%.4f")
            with r3:
                st.markdown("**D14**")
                ret_d14_loc = st.number_input("í‰ê· ", value=default_paid['retention_d14']['loc'], key="d14_loc", format="%.4f")
                ret_d14_scale = st.number_input("í‘œì¤€í¸ì°¨", value=default_paid['retention_d14']['scale'], key="d14_scale", format="%.4f")
            with r4:
                st.markdown("**D30**")
                ret_d30_loc = st.number_input("í‰ê· ", value=default_paid['retention_d30']['loc'], key="d30_loc", format="%.4f")
                ret_d30_scale = st.number_input("í‘œì¤€í¸ì°¨", value=default_paid['retention_d30']['scale'], key="d30_scale", format="%.4f")
            submitted = st.form_submit_button("ì±„ë„ ì¶”ê°€")
            if submitted:
                new_row_data = copy.deepcopy(default_paid)
                new_row_data.update({'os': os_val, 'country': country_val, 'name': name_val, 'product': product_val, 'type': type_val, 'budget_ratio': budget_val})
                new_row_data['cpi'] = {'loc': cpi_loc_val, 'scale': cpi_scale_val}
                new_row_data['payer_conversion_rate'] = {'a': pcr_a_val, 'b': pcr_b_val}
                new_row_data['arppu_d30'] = {'loc': arppu_loc_val, 'scale': arppu_scale_val}
                new_row_data['retention_d1'] = {'loc': ret_d1_loc, 'scale': ret_d1_scale}
                new_row_data['retention_d7'] = {'loc': ret_d7_loc, 'scale': ret_d7_scale}
                new_row_data['retention_d14'] = {'loc': ret_d14_loc, 'scale': ret_d14_scale}
                new_row_data['retention_d30'] = {'loc': ret_d30_loc, 'scale': ret_d30_scale}
                temp_scenario = {'media_mix': [{'os': os_val, 'channels': [{'country': country_val, 'media': [new_row_data]}]}]}
                flat_row = flatten_scenario_df(temp_scenario, 'media_mix')
                st.session_state.media_mix_df = pd.concat([st.session_state.media_mix_df, flat_row], ignore_index=True)
                st.session_state.show_add_channel_form = False
                st.rerun()

    if st.session_state.show_add_channel_form:
        render_add_channel_form()

    with st.expander("5. ìœ ë£Œ ì±„ë„ ë¯¹ìŠ¤", expanded=not st.session_state.show_add_channel_form):
        if st.button("ğŸ“¢ ìƒˆë¡œìš´ ì±„ë„ ì¶”ê°€", key="add_paid_channel_btn"):
            st.session_state.show_add_channel_form = True
            st.rerun()
        st.session_state.media_mix_df = st.data_editor(st.session_state.media_mix_df, num_rows="dynamic", use_container_width=True, key="media_mix_editor", column_config={"budget_ratio": st.column_config.NumberColumn("ì˜ˆì‚° (ì ˆëŒ€ê°’)", format="%d")})
        st.download_button(label="CSVë¡œ ë‚´ë³´ë‚´ê¸°", data=st.session_state.media_mix_df.to_csv(index=False).encode('utf-8-sig'), file_name='media_mix.csv', mime='text/csv')
    
    st.divider()

    def render_add_organic_form():
        with st.form(key="add_organic_form"):
            st.subheader("ğŸŒ± ìƒˆë¡œìš´ ìì—° ìœ ì… êµ­ê°€ ì¶”ê°€")
            default_org = st.session_state.config['default_rows']['organic']
            country_val = st.text_input("êµ­ê°€", default_org['country'])
            st.markdown("<h6>ì„±ê³¼ ì§€í‘œ</h6>", unsafe_allow_html=True)
            m1, m2, m3 = st.columns(3)
            with m1:
                st.markdown("**ì¼ë³„ ì„¤ì¹˜ ìˆ˜**")
                installs_loc_val = st.number_input("í‰ê·  (loc)", value=default_org['daily_installs']['loc'], key="org_inst_loc")
                installs_scale_val = st.number_input("í‘œì¤€í¸ì°¨ (scale)", value=default_org['daily_installs']['scale'], key="org_inst_scale")
            with m2:
                st.markdown("**ê²°ì œ ì „í™˜ìœ¨**")
                pcr_a_val = st.number_input("ì„±ê³µ (a)", value=default_org['payer_conversion_rate']['a'], key="org_pcr_a")
                pcr_b_val = st.number_input("ì‹¤íŒ¨ (b)", value=default_org['payer_conversion_rate']['b'], key="org_pcr_b")
            with m3:
                st.markdown("**ARPPU D30**")
                arppu_loc_val = st.number_input("í‰ê·  (loc)", value=default_org['arppu_d30']['loc'], key="org_arppu_loc")
                arppu_scale_val = st.number_input("í‘œì¤€í¸ì°¨ (scale)", value=default_org['arppu_d30']['scale'], key="org_arppu_scale")
            st.markdown("<h6>ë¦¬í…ì…˜ ì§€í‘œ</h6>", unsafe_allow_html=True)
            r1, r2, r3, r4 = st.columns(4)
            with r1:
                st.markdown("**D1**")
                ret_d1_loc = st.number_input("í‰ê· ", value=default_org['retention_d1']['loc'], key="org_d1_loc", format="%.4f")
                ret_d1_scale = st.number_input("í‘œì¤€í¸ì°¨", value=default_org['retention_d1']['scale'], key="org_d1_scale", format="%.4f")
            with r2:
                st.markdown("**D7**")
                ret_d7_loc = st.number_input("í‰ê· ", value=default_org['retention_d7']['loc'], key="org_d7_loc", format="%.4f")
                ret_d7_scale = st.number_input("í‘œì¤€í¸ì°¨", value=default_org['retention_d7']['scale'], key="org_d7_scale", format="%.4f")
            with r3:
                st.markdown("**D14**")
                ret_d14_loc = st.number_input("í‰ê· ", value=default_org['retention_d14']['loc'], key="org_d14_loc", format="%.4f")
                ret_d14_scale = st.number_input("í‘œì¤€í¸ì°¨", value=default_org['retention_d14']['scale'], key="org_d14_scale", format="%.4f")
            with r4:
                st.markdown("**D30**")
                ret_d30_loc = st.number_input("í‰ê· ", value=default_org['retention_d30']['loc'], key="org_d30_loc", format="%.4f")
                ret_d30_scale = st.number_input("í‘œì¤€í¸ì°¨", value=default_org['retention_d30']['scale'], key="org_d30_scale", format="%.4f")
            submitted = st.form_submit_button("êµ­ê°€ ì¶”ê°€")
            if submitted:
                new_row_data = copy.deepcopy(default_org)
                new_row_data['country'] = country_val
                new_row_data['daily_installs'] = {'loc': installs_loc_val, 'scale': installs_scale_val}
                new_row_data['payer_conversion_rate'] = {'a': pcr_a_val, 'b': pcr_b_val}
                new_row_data['arppu_d30'] = {'loc': arppu_loc_val, 'scale': arppu_scale_val}
                new_row_data['retention_d1'] = {'loc': ret_d1_loc, 'scale': ret_d1_scale}
                new_row_data['retention_d7'] = {'loc': ret_d7_loc, 'scale': ret_d7_scale}
                new_row_data['retention_d14'] = {'loc': ret_d14_loc, 'scale': ret_d14_scale}
                new_row_data['retention_d30'] = {'loc': ret_d30_loc, 'scale': ret_d30_scale}
                flat_row = flatten_scenario_df({'organic_assumptions': [new_row_data]}, 'organic')
                st.session_state.organic_df = pd.concat([st.session_state.organic_df, flat_row], ignore_index=True)
                st.session_state.show_add_organic_form = False
                st.rerun()
    
    if st.session_state.show_add_organic_form:
        render_add_organic_form()

    with st.expander("4. ìì—° ìœ ì… ì„¤ì •", expanded=not st.session_state.show_add_organic_form):
        if st.button("ğŸŒ± ìƒˆë¡œìš´ êµ­ê°€ ì¶”ê°€", key="add_organic_country_btn"):
            st.session_state.show_add_organic_form = True
            st.rerun()
        st.session_state.organic_df = st.data_editor(st.session_state.organic_df, num_rows="dynamic", use_container_width=True, key="organic_editor")

# =====================================================================================
# Tab 1: Dashboard
# =====================================================================================
with tab1:
    selected_arppu_scenario = st.session_state.get('arppu_choice', 'ARPPU D30 (ê¸°ì¤€)')
    st.header(f"ğŸ“Š ëŒ€ì‹œë³´ë“œ & ê²°ê³¼: {selected_arppu_scenario}")
    
    if st.button("ğŸš€ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰", type="primary", key="run_sim_main"):
        with st.spinner(f"{selected_arppu_scenario} ì‹œë‚˜ë¦¬ì˜¤ë¡œ ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰í•©ë‹ˆë‹¤..."):
            current_scenario_template = copy.deepcopy(st.session_state.config['scenario_template'])
            current_scenario_template['media_mix'] = reconstruct_scenario_from_df(st.session_state.media_mix_df.copy(), 'media_mix')
            current_scenario_template['organic_assumptions'] = reconstruct_scenario_from_df(st.session_state.organic_df.copy(), 'organic')
            arppu_key = selected_arppu_scenario.split(" ")[0].lower()
            arppu_params = {'scenario': selected_arppu_scenario, 'uplift_rate': st.session_state.assumptions['arppu_scenario_weights'].get(f"{arppu_key}_uplift", 1.0)}
            all_df, final_df = run_cached_simulation(st.session_state.project_info, st.session_state.assumptions, st.session_state.assumptions['monte_carlo']['num_simulations'], current_scenario_template, arppu_params)
            st.session_state.simulation_results[selected_arppu_scenario] = {"all_df": all_df, "final_df": final_df, "scenario_used": current_scenario_template}
        st.success(f"{selected_arppu_scenario} ì‹œë®¬ë ˆì´ì…˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    if selected_arppu_scenario in st.session_state.simulation_results:
        results = st.session_state.simulation_results[selected_arppu_scenario]
        render_dashboard_summary(results['final_df'], st.session_state.project_info, st.session_state.assumptions)
        st.divider()
        render_detailed_metrics(results['final_df'])
        st.divider()
        render_main_charts(results['all_df'], results['final_df'], st.session_state.config, results['scenario_used'])
        st.divider()
        st.subheader("â¬‡ï¸ ì¼ë³„ ì˜ˆì¸¡ ë°ì´í„° ë‚´ë³´ë‚´ê¸°")
        export_df = results['all_df'].groupby(['day', 'os', 'country', 'name', 'product', 'type']).median().reset_index()
        st.download_button(label="ì¼ë³„ ìƒì„¸ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", data=export_df.to_csv(index=False).encode('utf-8-sig'), file_name=f"daily_prediction_{selected_arppu_scenario}.csv", mime="text/csv")
    else:
        st.info("'ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

# =====================================================================================
# Tab 3: Model Validation
# =====================================================================================
with tab3:
    st.header("ğŸ” ëª¨ë¸ ì‹ ë¢°ë„ í‰ê°€")
    st.subheader("1. ìˆ˜ë ´ í…ŒìŠ¤íŠ¸")
    st.info("ì‹œë®¬ë ˆì´ì…˜ íšŸìˆ˜ë¥¼ ëŠ˜ë ¤ê°ì— ë”°ë¼ ê²°ê³¼ê°’ì´ ì•ˆì •ì ìœ¼ë¡œ ìˆ˜ë ´í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.")
    if st.button("ìˆ˜ë ´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"):
        with st.spinner("ìˆ˜ë ´ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
            sim = AdvancedLaunchSimulator(st.session_state.project_info, st.session_state.assumptions, st.session_state.assumptions['monte_carlo']['num_simulations'], st.session_state.config['scenario_template'], {'scenario': 'ARPPU D30 (ê¸°ì¤€)', 'uplift_rate': 1.0})
            convergence_data = sim.run_convergence_test()
            st.plotly_chart(create_convergence_figure(convergence_data), use_container_width=True)
    
    st.divider()
    st.subheader("2. ë°±í…ŒìŠ¤íŒ…")
    st.info("ê³¼ê±° ì‹¤ì œ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì—¬, í˜„ì¬ ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì •ì´ ê³¼ê±° ì„±ê³¼ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ì„¤ëª…í•˜ëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤.")
    uploaded_file = st.file_uploader("ê³¼ê±° ì„±ê³¼ ë°ì´í„° ì—…ë¡œë“œ (CSV)", type="csv")
    if uploaded_file:
        try:
            actual_data = pd.read_csv(uploaded_file)
            required_cols = ['day', 'actual_roas']
            if all(col in actual_data.columns for col in required_cols):
                actual_data = actual_data[required_cols].astype({'day': 'int', 'actual_roas': 'float'})
                st.dataframe(actual_data.head())
                if st.button("ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰"):
                    with st.spinner("ë°±í…ŒìŠ¤íŒ… ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
                        backtest_scenario = copy.deepcopy(st.session_state.config['scenario_template'])
                        backtest_scenario['media_mix'] = reconstruct_scenario_from_df(st.session_state.media_mix_df.copy(), 'media_mix')
                        backtest_scenario['organic_assumptions'] = reconstruct_scenario_from_df(st.session_state.organic_df.copy(), 'organic')
                        all_df_backtest, _ = run_cached_simulation(st.session_state.project_info, st.session_state.assumptions, 300, backtest_scenario, {'scenario': 'ARPPU D30 (ê¸°ì¤€)', 'uplift_rate': 1.0})
                        sim_median_roas = all_df_backtest.groupby('day')['paid_roas'].median().reset_index().rename(columns={'paid_roas': 'predicted_roas'})
                        comparison_df = pd.merge(actual_data, sim_median_roas, on='day', how='left').dropna()
                        rmse, mape = calculate_errors(comparison_df['actual_roas'], comparison_df['predicted_roas'])
                        st.plotly_chart(create_backtesting_figure(all_df_backtest, actual_data), use_container_width=True)
                        c1, c2 = st.columns(2)
                        c1.metric("RMSE", f"{rmse:.4f}")
                        c2.metric("MAPE", f"{mape:.2f}%")
            else:
                st.error(f"CSV íŒŒì¼ì— ë‹¤ìŒ í•„ìˆ˜ ì»¬ëŸ¼ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤: {', '.join(required_cols)}")
        except Exception as e:
            st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

